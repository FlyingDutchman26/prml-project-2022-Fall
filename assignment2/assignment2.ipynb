{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fudan RPML Assignment2: Deep Learning Meets News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![news](./news.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Your name and Student ID: [李培基], [20307140044]**\n",
    "\n",
    "Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this assignment, you will build a **text classification** system which is a fundamental task in the field of Natural Language Processing (NLP). More precisely, you are given a news classification task, assigning given news texts to the categories to which they belong. Unlike traditional classification tasks, **we did not provide you with any labels for this assignment, and you need to find a way to construct labels for these articles**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For this assignment you can use commonly used deep learning frameworks like paddle and pytorch, and **should use at least one kind of deep neural network for this task**. **You can use pretrained word vectors like Glove, but not pretrained large models like BERT.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The current computing device is cuda \n",
      "The current GPU is :GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# setup code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "args = {\n",
    "    'learning_rate':0.0004, \n",
    "    'first_momentum':0.9,\n",
    "    'second_momentum':0.999,\n",
    "    'batch_size':32,\n",
    "    'len_feature':300, # embedding_dim\n",
    "    'hidden_size':50,\n",
    "    'dropout':0.5,\n",
    "    'iter_times':50,\n",
    "    'num_class':3,\n",
    "    'train_rate':0.6,\n",
    "    'dev_rate':0.2,\n",
    "    'truncated':30,\n",
    "    'filter_num':100, # 原论文为100(不过原论文是英文数据集)\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"The current computing device is {device.type} \")\n",
    "if torch.cuda.is_available():\n",
    "    print(f'The current GPU is :{torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "什么企业适合开展融资租赁业务？你不看，真的吃大亏了！\n",
      "你见过苗寨里待客的方式吗？网友调侃：这才是真正的不醉不归啊！\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'assignment2_news.pkl'\n",
    "\n",
    "all_data = None\n",
    "with open(dataset_path,'rb') as fin:\n",
    "    all_data = pickle.load(fin)\n",
    "\n",
    "print(all_data[10343])\n",
    "print(all_data[78883])\n",
    "# 明显，这是一个中文新闻标题数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Exploratory Data Analysis (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集句子总数 83360\n",
      "数据集字符最长/最短长度: 145 / 2\n",
      "数据集中最长字符的句子:\n",
      " 【定了！中日双方签署有关经贸合作协议】5月9日，在李克强总理和安倍晋三首相共同见证下，中国商务部钟山部长与日本经济产业大臣世耕弘成共同签署了《关于加强服务贸易合作的备忘录》，中国国家发展改革委、商务部与日本外务省、经济产业省共同签署了《关于中日第三方市场合作的备忘录》。详细内容，请戳大图↓\n",
      "数据集中最短字符的句子:\n",
      " 美国\n",
      "数据集中句子字符长度平均值: 22.235280710172745\n",
      "数据集中句子字符长度超过 50 的句子数目: 66 / 83360\n",
      "因此结合句子长度分布图，我们有理由在后续处理时对句子长度进行截取\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "print('数据集句子总数',len(all_data))\n",
    "min_len = 9999\n",
    "max_len = 0\n",
    "id_1 = -1\n",
    "id_2 = -1\n",
    "len_list = []\n",
    "for idx,sentence in enumerate(all_data,0):\n",
    "    l = len(sentence)\n",
    "    if l > max_len:\n",
    "        max_len = l\n",
    "        id_1 = idx\n",
    "    if l < min_len:\n",
    "        min_len = l\n",
    "        id_2 = idx\n",
    "    len_list.append(l)\n",
    "print('数据集字符最长/最短长度:',max_len,'/',min_len)\n",
    "print('数据集中最长字符的句子:\\n',all_data[id_1])\n",
    "print('数据集中最短字符的句子:\\n',all_data[id_2])\n",
    "print('数据集中句子字符长度平均值:',sum(len_list)/len(len_list))\n",
    "print('数据集中句子字符长度超过 50 的句子数目:',sum(np.array(len_list) > 50),'/',len(all_data))\n",
    "print('因此结合句子长度分布图，我们有理由在后续处理时对句子长度进行截取')\n",
    "plt.title('Proportion of sequence length')\n",
    "plt.hist(len_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Tokenizer.cut at 0x7f5b1d37b2a0>\n",
      "【 定 了 ！ 中日 双方 签署 有关 经贸合作 协议 】 5 月 9 日 ， 在 李克强 总理 和 安倍晋三 首相 共同 见证 下 ， 中国 商务部 钟山 部长 与 日本 经济 产业 大臣 世耕弘成 共同 签署 了 《 关于 加强 服务 贸易 合作 的 备忘录 》 ， 中国 国家 发展 改革 委 、 商务部 与 日本外务省 、 经济 产业省 共同 签署 了 《 关于 中日 第三方 市场 合作 的 备忘录 》 。 详细 内容 ， 请 戳 大图 ↓\n",
      "['【', '定', '了', '！', '中日', '双方', '签署', '有关', '经贸合作', '协议', '】', '5', '月', '9', '日', '，', '在', '李克强', '总理', '和', '安倍晋三', '首相', '共同', '见证', '下', '，', '中国', '商务部', '钟山', '部长', '与', '日本', '经济', '产业', '大臣', '世耕弘成', '共同', '签署', '了', '《', '关于', '加强', '服务', '贸易', '合作', '的', '备忘录', '》', '，', '中国', '国家', '发展', '改革', '委', '、', '商务部', '与', '日本外务省', '、', '经济', '产业省', '共同', '签署', '了', '《', '关于', '中日', '第三方', '市场', '合作', '的', '备忘录', '》', '。', '详细', '内容', '，', '请', '戳', '大图', '↓']\n"
     ]
    }
   ],
   "source": [
    "# 尝试jieba分词效果\n",
    "import jieba\n",
    "seg_list = jieba.cut(\"【定了！中日双方签署有关经贸合作协议】5月9日，在李克强总理和安倍晋三首相共同见证下，中国商务部钟山部长与日本经济产业大臣世耕弘成共同签署了《关于加强服务贸易合作的备忘录》，中国国家发展改革委、商务部与日本外务省、经济产业省共同签署了《关于中日第三方市场合作的备忘录》。详细内容，请戳大图↓\")  # 默认是精确模式\n",
    "print(seg_list)\n",
    "print(\" \".join(seg_list))\n",
    "seg_list = jieba.lcut(\"【定了！中日双方签署有关经贸合作协议】5月9日，在李克强总理和安倍晋三首相共同见证下，中国商务部钟山部长与日本经济产业大臣世耕弘成共同签署了《关于加强服务贸易合作的备忘录》，中国国家发展改革委、商务部与日本外务省、经济产业省共同签署了《关于中日第三方市场合作的备忘录》。详细内容，请戳大图↓\")\n",
    "print(seg_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3. Construct the Labels (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 average_word_embedding + K-means聚类\n",
    "1. 首先利用jieba分词，去除只有一个词的文本，并去除中文停用词，获得分词后的文本数据集\n",
    "2. 之后使用预训练的word_vector标注每一个句子中的单词，然后对这些单词向量取平均，获得每个句子的sentence_embedding，最后再进行K-means聚类，将数据集中的句子无监督的进行分类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 加载预训练的word_embedding [365076,300]\n",
    "# sgns.sogounews.bigram-char sgns.sogou.char\n",
    "with open('sgns.sogou.char','rb') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "trained_dict = dict()\n",
    "n = len(lines)  # 为预训练文件总行数\n",
    "embedding_dim = len(lines[1].split())-1\n",
    "for i in range(1,n):\n",
    "    # 因为第一行不是数据 共365076的词/字 每个被映射到300维空间\n",
    "    line = lines[i].split()\n",
    "    trained_dict[line[0].decode('utf-8')] = [float(line[j]) for j in range(1,embedding_dim+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.918 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 用jieba 进行中文分词\n",
    "data = []\n",
    "for sentence in all_data:\n",
    "    seg_list = [w for w in jieba.cut(sentence) if len(w) > 1]\n",
    "    if len(seg_list) > 1 and seg_list != '\\r\\t':\n",
    "        data.append(seg_list)\n",
    "#停用词加载\n",
    "stopwords = pd.read_table('stopwords.txt',names = ['stopword'],quoting = 3)\n",
    "\n",
    "df_content = pd.DataFrame({'data':data})\n",
    "#去除停用词\n",
    "def drop_stopwords(contents,stopwords):\n",
    "    contents_clean = []\n",
    "    all_words = []\n",
    "    for line in contents:\n",
    "        line_clean = []\n",
    "        for word in line:\n",
    "            if word in stopwords:\n",
    "                continue\n",
    "            line_clean.append(word)\n",
    "            all_words.append(word)\n",
    "        contents_clean.append(line_clean)\n",
    "    return contents_clean,all_words\n",
    "\n",
    "data = df_content.data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集句子总数 83175\n",
      "数据集最长/最短长度: 48 / 2\n",
      "数据集中最多词的句子:\n",
      " ['中日', '双方', '签署', '有关', '经贸合作', '协议', '李克强', '总理', '安倍晋三', '首相', '共同', '见证', '中国', '商务部', '钟山', '部长', '日本', '经济', '产业', '大臣', '世耕弘成', '共同', '签署', '关于', '加强', '服务', '贸易', '合作', '备忘录', '中国', '国家', '发展', '改革', '商务部', '日本外务省', '经济', '产业省', '共同', '签署', '关于', '中日', '第三方', '市场', '合作', '备忘录', '详细', '内容', '大图']\n",
      "数据集中最少词的句子:\n",
      " ['都江堰', '景区']\n",
      "数据集中词长度长度平均值: 7.518352870453862\n",
      "数据集中词数量超过 30 的句子数目: 5 / 83175\n"
     ]
    }
   ],
   "source": [
    "# 使用中文分词后 数据集句子的长度分析\n",
    "print('数据集句子总数',len(data))\n",
    "min_len = 9999\n",
    "max_len = 0\n",
    "id_1 = -1\n",
    "id_2 = -1\n",
    "len_list = []\n",
    "for idx,sentence in enumerate(data,0):\n",
    "    l = len(sentence)\n",
    "    if l > max_len:\n",
    "        max_len = l\n",
    "        id_1 = idx\n",
    "    if l < min_len:\n",
    "        min_len = l\n",
    "        id_2 = idx\n",
    "    len_list.append(l)\n",
    "print('数据集最长/最短长度:',max_len,'/',min_len)\n",
    "print('数据集中最多词的句子:\\n',data[id_1])\n",
    "print('数据集中最少词的句子:\\n',data[id_2])\n",
    "print('数据集中词长度长度平均值:',sum(len_list)/len(len_list))\n",
    "print('数据集中词数量超过 30 的句子数目:',sum(np.array(len_list) > 30),'/',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote-home/pjli/anaconda3/envs/nlptorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "class Embedding():\n",
    "    def __init__(self,trained_dict,data,args) -> None:\n",
    "        self.dict_words = {}    # 单词映射到自然数的字典\n",
    "        self.sentence_matrix = []   # 数据集中句子的矩阵表示（每个词为一个自然数）\n",
    "        self.embedding_matrix = [] # embedding矩阵，每个word_vector对应的下标id为相应的词\n",
    "        self.trained_dict = trained_dict  # 预训练的词典：词与word_vector的对应\n",
    "        self.embedding_dim = args['len_feature'] # embedding dim\n",
    "        self.data = data # 分词后的数据集\n",
    "        self.sentence_vector = [] # 数据集每个句子的向量表示(sentence embedding)\n",
    "        self.labels = None\n",
    "    \n",
    "    def get_words(self):\n",
    "        '''\n",
    "        此函数的目标是建立单词与自然数的映射的词典,同时建立好embedding_weight矩阵,并不处理数据集\n",
    "        '''\n",
    "        self.embedding_matrix.append([0]*self.embedding_dim) # [PAD] id:0\n",
    "        self.embedding_matrix.append([0]*self.embedding_dim) # [UNK] id:1\n",
    "        self.dict_words['[PAD]'] = 0\n",
    "        self.dict_words['[UNK]'] = 1\n",
    "        for word in self.trained_dict.keys():\n",
    "            if word not in self.dict_words:\n",
    "                self.dict_words[word] = len(self.dict_words) + 2\n",
    "                self.embedding_matrix.append(self.trained_dict[word])\n",
    "        mean = torch.mean(torch.tensor(self.embedding_matrix))\n",
    "        std = torch.std(torch.tensor(self.embedding_matrix))\n",
    "        unknown_vec = torch.normal(mean,std,size = [1,self.embedding_dim]).reshape(-1)\n",
    "        self.embedding_matrix[1] = unknown_vec.tolist()    # for [UNK]： Gaussian Sample 有的论文做法\n",
    "    \n",
    "    def get_id(self):\n",
    "        '''\n",
    "        这个函数目的是给数据集中的句子建立成矩阵，每个句子表示为一串id，对应着 embedding矩阵的 下标\n",
    "        '''\n",
    "        for sentence in self.data:\n",
    "            item = []\n",
    "            for word in sentence:\n",
    "                if word not in self.dict_words:\n",
    "                    item.append(self.dict_words['[UNK]'])\n",
    "                else:\n",
    "                    item.append(self.dict_words[word])\n",
    "            self.sentence_matrix.append(item)\n",
    "    \n",
    "    def average_sen2vec(self):\n",
    "        '''\n",
    "        此函数的目标是做一个sentence_embedding,即sen2vec\n",
    "        '''\n",
    "        for sentence in self.sentence_matrix:\n",
    "            sum_vec = np.array([0.0]*self.embedding_dim,dtype = 'float32')\n",
    "            sentence_length = len(sentence)\n",
    "            for idx in sentence:\n",
    "                word_vec = np.array(self.embedding_matrix[idx],dtype = 'float32')\n",
    "                sum_vec = sum_vec + word_vec\n",
    "            self.sentence_vector.append( (sum_vec/sentence_length).tolist() )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebd = Embedding(trained_dict=trained_dict,data=data,args=args)\n",
    "ebd.get_words()\n",
    "ebd.get_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebd.average_sen2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ebd.sentence_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此部分仅是实验一下效果\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "X = np.array(m)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
    "news_data = []\n",
    "for idx,sentence in enumerate(data,0):\n",
    "    item = [sentence] + [kmeans.labels_[idx]]\n",
    "    news_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83175\n",
      "[['经济学家', '吴敬琏', '为什么', '反对', '不惜代价', '发展', '芯片', '产业'], 0]\n",
      "[['如何', '评价', '许鞍华', '导演', '电影', '为什么', '总能', '给人以', '触动'], 0]\n",
      "[['规划', '公示', '苏州', '古城区', '变化'], 0]\n",
      "[['放任', '台独', '叫嚣', '英文', '戳破', '现状'], 0]\n",
      "[['方舟子', '象棋', '源自', '印度', '中国', '古代', '没有', '大象', '认为', '这种', '说法', '怎么样'], 0]\n",
      "[['高考', '志愿', '影响', '未来'], 0]\n",
      "[['2018', '航天', '领域', '发生', '哪些', '期待'], 0]\n",
      "[['古希腊', '众神', '那点', '事儿'], 0]\n",
      "[['缅甸', '人民', '云南', '瑞丽', '幸福生活'], 0]\n",
      "[['为什么', '股东', '人数', '大幅', '减少', '筹码', '更为', '集中', '股票', '一直', '下跌'], 0]\n",
      "[['郭德纲', '恩师', '侯耀文', '出身', '名门', '一生', '显赫', '死后', '四年', '得以', '入土为安'], 0]\n",
      "[['农产品', '怎么', '才能', '赚大钱', '大家', '过来'], 0]\n",
      "[['智能', '制造', '产业园', '落户', '高新区'], 0]\n",
      "[['夏普', '推出', '机器人', '手机', '售价', '11000', '人民币', '功能齐全', '长得', '很萌'], 0]\n",
      "[['2018', '巴西', '大豆', '产量', '历史', '纪录', '中国', '买家', '好消息'], 0]\n",
      "[['月份', '巴中', '城区', '鲜菜', '价格', '降幅', '收窄'], 0]\n",
      "[['广东', '哪个', '地方', '茶叶', '出名'], 0]\n",
      "[['美国', '生活', '怎么', '公寓'], 0]\n",
      "[['美丽', '乡村', '温州'], 0]\n",
      "[['潜伏', '蒋介石', '身边', '女特工', '凭借', '特殊', '能力', '重用', '后来', '结局', '如何'], 0]\n",
      "[['民宿', '发展', '乡村', '旅游业', '发展', '必要', '联系'], 0]\n",
      "[['如何', '看待', '一亿', '90', '半夜', '两点', '糟蹋', '自己', '这种', '现象'], 0]\n",
      "[['如果', '日本', '国土', '滑向', '海沟', '沉没', '要求', '中国', '人民', '收留', '作为', '中国', '接受', '日本'], 0]\n",
      "[['马云', '判断', '未来', '房价', '便宜', '白菜', '基于', '什么', '逻辑'], 0]\n",
      "[['感受', '古代', '波斯', '帝国', '久远', '历史', '文明', '东西南北', '重要', '城市', '一次', '游历'], 0]\n",
      "[['官方', '发文', '规范', '民间', '借贷', '未经', '批准', '不得', '从事', '放贷', '业务'], 0]\n",
      "[['磷酸', '价格', '大幅', '下跌', '相关', '上市公司', '承压', '明显', '影响'], 0]\n",
      "[['大学生', '农村', '老家', '发现', '姐姐', '工地', '结果', '却说', '这样', '一段话'], 0]\n",
      "[['巴厘岛', '旅游', '是否', '见到'], 0]\n",
      "[['军事', '美国', '海军', '最新型', '高速', '双体船', '海上', '测试'], 0]\n",
      "[['为什么', '歌曲', '日语', '填词', '容易'], 0]\n",
      "[['上海', '孟买', '相比', '哪个', '城市', '发达'], 0]\n",
      "[['聆听', '千手观音', '菩萨', '我们', '静心', '之旅', '所求', '如意', '随心'], 0]\n",
      "[['投票', '事件', '过后', '联想', '今后', '日子', '怎样'], 0]\n",
      "[['复仇者', '联盟', '导演', '接受', '采访', '直言', '勒布朗', '詹姆斯', '就是', '一名', '超级', '英雄', '怎么'], 0]\n",
      "[['乘风破浪', '热血', '奋战', '奔跑', '龙舟赛', '感动', '全网'], 0]\n",
      "[['国际', '运输', '船舶', '增值税', '退税', '管理', '办法', '出台'], 0]\n",
      "[['宁夏', '这些', '单位', '招人', '银行', '事业单位'], 0]\n",
      "[['越南', '语言不通', '怎么办'], 0]\n",
      "[['精神', '再现', '兄弟', '初心', '团结', '同行'], 0]\n",
      "[['山东', '未来', '高铁', '规划', '落户', '这个', '地级市'], 0]\n",
      "[['兵哥哥', '教师', '对象', '理由'], 0]\n",
      "[['美国', '航母', '手段', '哪些'], 0]\n",
      "[['秦始皇', '修建', '万里长城', '换算', '人民币', '多少', '数字', '惊人'], 0]\n",
      "[['都江堰', '景区'], 0]\n",
      "[['如何', '看待', '梅西', '体系', '球员', '观点', '认为', '这个', '说法', '道理'], 0]\n",
      "[['蒙古', '多少', '海军'], 0]\n",
      "[['今日', 'WWE', '资讯', '尼基', '贝拉', '约翰', '塞纳', '仍然', '同居', '卡斯', '自毁前程'], 0]\n",
      "[['媲美', '三峡', '四川', '这个', '旷世', '幽谷', '中国', '开放'], 0]\n",
      "[['联想', '活多久'], 0]\n",
      "[['空置', '房子', '是否', '可以', '抵押', '贷款', '方式', '获取', '资金', '防止', '降价'], 0]\n",
      "[['成都', '高新区', '启动', '熊猫', '人才', '专项', '奖励', '申报'], 0]\n",
      "[['怎么', '写出', '一个', '前期', '淘宝', '标题'], 0]\n",
      "[['重庆', '西安', '哪个', '城市', '更好'], 0]\n",
      "[['努力', '造成', '城市', '音乐', '名片'], 0]\n",
      "[['自由泳', '入水'], 0]\n",
      "[['选手', '热血', '舞团', '投票', '不公', '随后', '导演', '的话', '暗示', '一切'], 0]\n",
      "[['我国', '天宫', '空间站', '能否', '取代', '国际', '空间站', '成为', '一个', '国际', '空间站'], 0]\n",
      "[['投票', '事件', '过后', '联想', '今后', '日子', '怎样'], 0]\n",
      "[['为什么', '五笔', '落伍'], 0]\n",
      "[['周星驰', '为何', '终身'], 0]\n",
      "[['见微知著', '公馆', '细节', '筑造', '美好', '社区'], 0]\n",
      "[['动物', '慢镜头', '慢点', '视频'], 0]\n",
      "[['上课时', '学生', '手机', '响个', '不停', '老师', '一怒之下', '手机', '家长', '发票', '老师', '大家', '怎么', '看待', '这种'], 0]\n",
      "[['婆婆', '儿子', '酒席', '回家', '孩子', '满身', '红斑', '解释', '不能', '忍受'], 0]\n",
      "[['外地人', '济南', '旅游', '买点', '什么', '济南', '特产'], 0]\n",
      "[['上联', '琴棋书画', '秀才', '下联', '怎么'], 0]\n",
      "[['加密', '货币', '其实', '一个', '麻烦', '支付', '系统'], 0]\n",
      "[['凯尔特人', '领先', '76', '为什么', '赛前', 'ESPN21', '专家', '18', '预测', '76', '晋级'], 0]\n",
      "[['中东', '日益', '紧张局势', '金价', '是否', '还有', '上涨', '空间'], 0]\n",
      "[['迈克', '杰克逊', '代表', '美国', '憨豆', '先生', '代表', '英国', '中国'], 0]\n",
      "[['真人', 'CS', '可以', '代替', '实战', '训练'], 0]\n",
      "[['淄博', '周村区', '13', '停水', '信息'], 0]\n",
      "[['三四十', '年代', '北京', '行当'], 0]\n",
      "[['为什么', '有些', '溧阳', '河南', '终于', '找到', '原因'], 0]\n",
      "[['保定市', '人民政府', '关于', '主城区', '主要', '出入口', '启用', '车辆', '限高', '设施', '通告'], 0]\n",
      "[['日本', '26', '女星', '遇难', '瘫痪', '经纪', '公司', '能量', '发声', '全力支持'], 0]\n",
      "[['中华', '健身', '学院', '专业', '健身', '教练', '培训', '摇篮'], 0]\n",
      "[['需要', '了解', '一下'], 0]\n",
      "[['特朗普', '行为', '导致', '伊朗', '军事冲突', '加剧', '德黑兰', '加快', '开发', '核武器'], 0]\n",
      "[['独一无二', '震撼'], 0]\n",
      "[['妈妈', '遗照', '清华', '湖南', '文科', '状元', '故事', '令人', '感慨万千'], 0]\n",
      "[['空军', '双料', '王牌', '寿终正寝', '曾经', '冒险', '试飞', '驾机', '首创', '超音速', '纪录'], 0]\n",
      "[['旅行车', '真的', '豪华'], 0]\n",
      "[['程序', '创业', '风口', '持续', '火热', '当下', '哪些', '领域', '适合', '创业者'], 0]\n",
      "[['如何', '判断', '一个', '是否', '具备', '管理', '能力'], 0]\n",
      "[['中国', '慈善', '捐款', '最多', '哪些'], 0]\n",
      "[['楼市', '怎样', '炒热'], 0]\n",
      "[['复仇者', '联盟', '银河', '护卫队', '唯一', '下来'], 0]\n",
      "[['浙江', '海翔', '药业', '股份', '有限公司'], 0]\n",
      "[['可能', '今年', '听过', '最好', '演讲', '任何人', '打乱', '人生', '节奏'], 0]\n",
      "[['旅游', '景区', '飞机', '大炮', '坦克', '这些', '现代', '兵器', '装备', '哪里', '知道'], 0]\n",
      "[['复仇者', '联盟', '变成', '灰烬', '最后', '真的'], 0]\n",
      "[['究竟', '腊梅', '还是', '蜡梅', '到底', '哪个'], 0]\n",
      "[['阿坝州', '理县', '小朋友', '感受', '民族', '民俗文化', '视频'], 0]\n",
      "[['后院起火', '普京', '核战争', '避难所', '突然', '撬门', '偷窃', '盗贼', '有备而来'], 0]\n",
      "[['中国足协', '使用', '长达', '34', '会徽', '进行', '微调', '发布', '会徽', '怎么', '评价'], 0]\n",
      "[['原汁原味', '联大', '牵动', '神思'], 0]\n",
      "[['特朗普', '为什么', '可以', '随意', '废除', '此前', '美国政府', '达成', '各种', '协议'], 0]\n",
      "[['如果', '范冰冰', '嫁给'], 0]\n",
      "[['刺激', '战场', '如何', '选择', '枪械', '搭配'], 0]\n",
      "[['散户', '应该', '怎么', '股市', '永久', '不衰', '长期', '发展'], 0]\n",
      "[['刺激', '战场', '三大', '幻觉', '什么'], 0]\n",
      "[['美国', '是不是', '分裂主义', '国家'], 0]\n",
      "[['人工智能', '娃娃', '抓起', '贝尔', '科教', '发布', '一对一', '编程', '授课', '服务'], 0]\n",
      "[['内外交困', '内塔尼亚胡', '是不是', '失去', '以色列', '统治'], 0]\n",
      "[['上海', '民办', '中小学', '报名', '降温', '预计', '录取', '比例', '大幅', '上升'], 0]\n"
     ]
    }
   ],
   "source": [
    "# 我们测试一下分类效果\n",
    "print(len(news_data))\n",
    "for i in range(200):\n",
    "    s = news_data[i][1]\n",
    "    if s == 0:\n",
    "        print(news_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 1 0 0 0 0 1 0 2 0 0 1 1 0 0 1 0 0]\n",
      "[['经济学家', '吴敬琏', '为什么', '反对', '不惜代价', '发展', '芯片', '产业'], ['颜值', '一双', '美腿', '甚至', '可以', '忽略', '颜值'], ['转自', '常德', '诗人', '再访', '桃花源', '再续', '心灵', '故乡', '故事'], ['虎牙', '拼杀', '四年', '游戏', '直播', '第一股', '真正', '挑战', '才刚', '开始'], ['如何', '评价', '许鞍华', '导演', '电影', '为什么', '总能', '给人以', '触动'], ['规划', '公示', '苏州', '古城区', '变化'], ['放任', '台独', '叫嚣', '英文', '戳破', '现状'], ['方舟子', '象棋', '源自', '印度', '中国', '古代', '没有', '大象', '认为', '这种', '说法', '怎么样'], ['徐小平', '投资', '100%', '看人', '创业者', '见面', '马上', '给钱'], ['高考', '志愿', '影响', '未来'], ['小米', 'mix2', 'vivox21', 'oppor15', '哪个', '性价比'], ['2018', '航天', '领域', '发生', '哪些', '期待'], ['古希腊', '众神', '那点', '事儿'], ['上联', '一生', '二生', '三生', '万物', '物物', '生辉', '怎么', '下联'], ['猪八戒', '为啥', '真武大帝', '不怕', '自吹', '不敢'], ['缅甸', '人民', '云南', '瑞丽', '幸福生活'], ['为什么', '股东', '人数', '大幅', '减少', '筹码', '更为', '集中', '股票', '一直', '下跌'], ['现金', '农村', '中小学', '教师', '三十年', '教龄', '荣誉证书', '你会选', '一个'], ['郭德纲', '恩师', '侯耀文', '出身', '名门', '一生', '显赫', '死后', '四年', '得以', '入土为安'], ['农产品', '怎么', '才能', '赚大钱', '大家', '过来']]\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.labels_[0:20])\n",
    "print(data[0:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 LDA主题模型\n",
    "LDA 主题模型又称隐性狄利克雷模型，是由2003的一篇论文 Latent Dirichlet Allocation提出，作者是 Blei D M, Ng A Y, Jordan M I，其中就有吴恩达老师。是一种无监督的用于将文档分类的机器学习方法，能够为每个主题生成关键词权重，同时可以给出一篇文档属于各个主题的的概率。\n",
    "\n",
    "1. 利用jieba分词，去除只有一个词的文本，并去除中文停用词，获得分词后的文本数据集\n",
    "2. 利用LDA模型将文本分类，因为得到主题都具有可解释性(具有关键词)，我们直接取每个文本具有最大概率的主题作为该条文本的标签，而不再进行聚类方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding():\n",
    "    def __init__(self,trained_dict,data,args) -> None:\n",
    "        self.dict_words = {}    # 单词映射到自然数的字典\n",
    "        self.sentence_matrix = []   # 数据集中句子的矩阵表示（每个词为一个自然数）\n",
    "        self.embedding_matrix = [] # embedding矩阵，每个word_vector对应的下标id为相应的词\n",
    "        self.trained_dict = trained_dict  # 预训练的词典：词与word_vector的对应\n",
    "        self.embedding_dim = args['len_feature'] # embedding dim\n",
    "        self.data = data # 分词后的数据集\n",
    "        self.sentence_vector = [] # 数据集每个句子的向量表示(sentence embedding)\n",
    "        self.labels = None\n",
    "    \n",
    "    def get_words(self):\n",
    "        '''\n",
    "        此函数的目标是建立单词与自然数的映射的词典,同时建立好embedding_weight矩阵,并不处理数据集\n",
    "        '''\n",
    "        self.embedding_matrix.append([0]*self.embedding_dim) # [PAD] id:0\n",
    "        self.embedding_matrix.append([0]*self.embedding_dim) # [UNK] id:1\n",
    "        self.dict_words['[PAD]'] = 0\n",
    "        self.dict_words['[UNK]'] = 1\n",
    "        for word in self.trained_dict.keys():\n",
    "            if word not in self.dict_words:\n",
    "                self.dict_words[word] = len(self.dict_words) + 2\n",
    "                self.embedding_matrix.append(self.trained_dict[word])\n",
    "        mean = torch.mean(torch.tensor(self.embedding_matrix))\n",
    "        std = torch.std(torch.tensor(self.embedding_matrix))\n",
    "        unknown_vec = torch.normal(mean,std,size = [1,self.embedding_dim]).reshape(-1)\n",
    "        self.embedding_matrix[1] = unknown_vec.tolist()    # for [UNK]： Gaussian Sample 有的论文做法\n",
    "    \n",
    "    def get_id(self):\n",
    "        '''\n",
    "        这个函数目的是给数据集中的句子建立成矩阵，每个句子表示为一串id，对应着 embedding矩阵的 下标\n",
    "        '''\n",
    "        for sentence in self.data:\n",
    "            item = []\n",
    "            for word in sentence:\n",
    "                if word not in self.dict_words:\n",
    "                    item.append(self.dict_words['[UNK]'])\n",
    "                else:\n",
    "                    item.append(self.dict_words[word])\n",
    "            self.sentence_matrix.append(item)\n",
    "    \n",
    "    def average_sen2vec(self):\n",
    "        '''\n",
    "        此函数的目标是做一个sentence_embedding,即sen2vec\n",
    "        '''\n",
    "        for sentence in self.sentence_matrix:\n",
    "            sum_vec = np.array([0.0]*self.embedding_dim,dtype = 'float32')\n",
    "            sentence_length = len(sentence)\n",
    "            for idx in sentence:\n",
    "                word_vec = np.array(self.embedding_matrix[idx],dtype = 'float32')\n",
    "                sum_vec = sum_vec + word_vec\n",
    "            self.sentence_vector.append( (sum_vec/sentence_length).tolist() )\n",
    "    \n",
    "    def get_labels(self,labels):\n",
    "        self.labels = labels\n",
    "        if len(labels) != len(self.data):\n",
    "            raise Exception('标签数量与数据集数量不相符')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sgns.sogou.char','rb') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "trained_dict = dict()\n",
    "n = len(lines)  # 为预训练文件总行数\n",
    "embedding_dim = len(lines[1].split())-1\n",
    "\n",
    "for i in range(1,n):\n",
    "    # 因为第一行不是数据 共365076的词/字 每个被映射到300维空间\n",
    "    line = lines[i].split()\n",
    "    trained_dict[line[0].decode('utf-8')] = [float(line[j]) for j in range(1,embedding_dim+1)]\n",
    "dataset_path = 'assignment2_news.pkl'\n",
    "\n",
    "all_data = None\n",
    "with open(dataset_path,'rb') as fin:\n",
    "    all_data = pickle.load(fin)\n",
    "content = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.922 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.006*\"上联\" + 0.006*\"下联\" + 0.005*\"手机\" + 0.003*\"看待\" + 0.003*\"王者\" + 0.003*\"荣耀\" + 0.003*\"游戏\" + 0.003*\"小米\" + 0.003*\"上市\" + 0.003*\"英雄\"'), (1, '0.006*\"网友\" + 0.006*\"农村\" + 0.004*\"知道\" + 0.003*\"孩子\" + 0.003*\"没有\" + 0.003*\"真的\" + 0.003*\"故事\" + 0.003*\"生活\" + 0.003*\"活动\" + 0.002*\"需要\"'), (2, '0.019*\"中国\" + 0.012*\"美国\" + 0.007*\"世界\" + 0.005*\"现在\" + 0.005*\"2018\" + 0.004*\"日本\" + 0.004*\"国家\" + 0.004*\"俄罗斯\" + 0.003*\"发展\" + 0.003*\"伊朗\"')]\n"
     ]
    }
   ],
   "source": [
    "#分词\n",
    "content_S = []\n",
    "for line in content:\n",
    "    current_segment = [w for w in jieba.cut(line) if len(w) > 1] # 分词\n",
    "    if len(current_segment) > 1 and current_segment != '\\r\\t':\n",
    "        content_S.append(current_segment)\n",
    "#分词结果转为DataFrame\n",
    "df_content = pd.DataFrame({'content_S':content_S})\n",
    "\n",
    "#停用词加载\n",
    "stopwords = pd.read_table('stopwords.txt',names = ['stopword'],quoting = 3)\n",
    "\n",
    "#去除停用词\n",
    "def drop_stopwords(contents,stopwords):\n",
    "    contents_clean = []\n",
    "    all_words = []\n",
    "    for line in contents:\n",
    "        line_clean = []\n",
    "        for word in line:\n",
    "            if word in stopwords:\n",
    "                continue\n",
    "            line_clean.append(word)\n",
    "            all_words.append(word)\n",
    "        contents_clean.append(line_clean)\n",
    "    return contents_clean,all_words\n",
    "\n",
    "contents = df_content.content_S.values.tolist()\n",
    "stopwords = stopwords.stopword.values.tolist()\n",
    "#contents_clean存储的是一个文本处理结果一个数组，all_words是将所有文本处理结果存储为1个数组\n",
    "contents_clean,all_words = drop_stopwords(contents,stopwords)\n",
    "\n",
    "#处理后的结果转化为DataFrame\n",
    "df_content = pd.DataFrame({'contents_clean':contents_clean})#文本处理结果\n",
    "df_all_words = pd.DataFrame({'all_words':all_words})#语料词典\n",
    "\n",
    "#统计语料词典中的词出现频率\n",
    "words_count = df_all_words.groupby(by=['all_words'])['all_words'].agg([('count',np.size)])\n",
    "words_count = words_count.reset_index().sort_values(by=['count'],ascending = False)#降序\n",
    "\n",
    "\n",
    "from gensim import corpora,models,similarities\n",
    "import gensim\n",
    "\n",
    "dictionary = corpora.Dictionary(contents_clean)\n",
    "corpus = [dictionary.doc2bow(sentence) for sentence in contents_clean]\n",
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=dictionary,num_topics=3,random_state=1)\n",
    "\n",
    "labels = []\n",
    "\n",
    "print(lda.print_topics(num_topics=3,num_words=10))\n",
    "#预测文本的主题\n",
    "for e, values in enumerate(lda.inference(corpus)[0]):\n",
    "    # print(contents[e])\n",
    "    max_value = -1\n",
    "    label = -1\n",
    "    for ee, value in enumerate(values):\n",
    "        # print('\\t主题%d推断值%.2f' % (ee, value))\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "            label = int(ee)\n",
    "    labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['经济学家', '吴敬琏', '为什么', '反对', '不惜代价', '发展', '芯片', '产业']\n",
      "['转自', '常德', '诗人', '再访', '桃花源', '再续', '心灵', '故乡', '故事']\n",
      "['放任', '台独', '叫嚣', '英文', '戳破', '现状']\n",
      "['2018', '航天', '领域', '发生', '哪些', '期待']\n",
      "['缅甸', '人民', '云南', '瑞丽', '幸福生活']\n",
      "['为什么', '股东', '人数', '大幅', '减少', '筹码', '更为', '集中', '股票', '一直', '下跌']\n",
      "['农产品', '怎么', '才能', '赚大钱', '大家', '过来']\n",
      "['2018', '巴西', '大豆', '产量', '历史', '纪录', '中国', '买家', '好消息']\n",
      "['伊拉克', '战争', '十二张', '照片', '战争', '面前', '任何人', '渺小']\n",
      "['一年级', '下册', '语文', '考试', '复习', '重点', '什么']\n",
      "['民宿', '发展', '乡村', '旅游业', '发展', '必要', '联系']\n",
      "['最具', '特色', '十大', '古村落', '中国', '才能', '看到', '绝无仅有']\n",
      "['如果', '日本', '国土', '滑向', '海沟', '沉没', '要求', '中国', '人民', '收留', '作为', '中国', '接受', '日本']\n",
      "['嘴仗', '结束', '伊朗', '局势', '升级', '中东', '热战', '开始', '美国', '为何', '积极', '点赞']\n",
      "['磷酸', '价格', '大幅', '下跌', '相关', '上市公司', '承压', '明显', '影响']\n",
      "['国内', '四款', '主要', '牵引车', '模型', '简单', '对比']\n",
      "['魔鬼', '任用', '氨水', '女友', '双眼', '兜风', '痛久点']\n",
      "['巴厘岛', '旅游', '是否', '见到']\n",
      "['军事', '美国', '海军', '最新型', '高速', '双体船', '海上', '测试']\n",
      "['为什么', '歌曲', '日语', '填词', '容易']\n",
      "['上海', '孟买', '相比', '哪个', '城市', '发达']\n",
      "['退出', '伊朗核', '协议', '而犯', '众怒', '美国会', '世界', '孤立']\n",
      "['光头', '十大', '当红', '女明星']\n",
      "['当假', '价格', '低于', '正品', '质量', '达标', '为什么', '选择', '正品']\n",
      "['英国', '进口', '开花', '300', '土里', '疯长', '30', '长成', '一片', '花海']\n",
      "['离婚', '四年', '前妻', '六万块', '八个']\n",
      "['兵哥哥', '教师', '对象', '理由']\n",
      "['美国', '航母', '手段', '哪些']\n",
      "['秦始皇', '修建', '万里长城', '换算', '人民币', '多少', '数字', '惊人']\n",
      "['都江堰', '景区']\n",
      "['蒙古', '多少', '海军']\n",
      "['那英要', '中国', '声音', '舞台', '永别']\n",
      "['今日', 'WWE', '资讯', '尼基', '贝拉', '约翰', '塞纳', '仍然', '同居', '卡斯', '自毁前程']\n",
      "['媲美', '三峡', '四川', '这个', '旷世', '幽谷', '中国', '开放']\n",
      "['联想', '活多久']\n",
      "['马伊', '探班', '文章', '闫妮', '一起', '聊天', '夫妻俩', '手牵手', '小秀', '一把', '恩爱']\n",
      "['叶公', '非公', '所好', '非龙']\n",
      "['大连', '一方', '战胜', '广州', '恒大', '是否', '预示', '万达', '王者', '归来']\n",
      "['低得', '惊人', 'EA', '曝光', 'Xbox', 'One', '生涯', '销量', '不如', 'N64']\n",
      "['重庆', '西安', '哪个', '城市', '更好']\n",
      "['聪明', '可爱', '迷你', '袖珍', '多少', '一匹', '赚钱', '利润', '成本', '怎么样']\n",
      "['我国', '天宫', '空间站', '能否', '取代', '国际', '空间站', '成为', '一个', '国际', '空间站']\n",
      "['玩乐', '就是', '态度', '宝骏', '510', '颜兽', '潮流', '街区', '郑州']\n",
      "['6.98', '万起', '省油', '省心', 'SUV', '实力', '不输', '合资']\n",
      "['想读', '核工程', '国防', '方向', '哪个', '大学', '比较']\n",
      "['为什么', '五笔', '落伍']\n",
      "['中东', '日益', '紧张局势', '金价', '是否', '还有', '上涨', '空间']\n",
      "['真实', '走进', '神话', '世界', '莽荒记', '国产', '标杆']\n",
      "['淄博', '周村区', '13', '停水', '信息']\n",
      "['河南', '有个', '天天', '吃土', '传说', '竟是', '愚公', '后人', '真的']\n",
      "['志强', '教父', '怎样', '减少', '不必要', '麻纺', '轻松自在']\n",
      "['雷凌', '卡罗', '明锐', '怎么', '选择']\n",
      "['特朗普', '行为', '导致', '伊朗', '军事冲突', '加剧', '德黑兰', '加快', '开发', '核武器']\n",
      "['独一无二', '震撼']\n",
      "['空军', '双料', '王牌', '寿终正寝', '曾经', '冒险', '试飞', '驾机', '首创', '超音速', '纪录']\n",
      "['字谜', '一来', '打一字', '简单', '字谜']\n",
      "['旅行车', '真的', '豪华']\n",
      "['中国', '古桥', '有多美']\n",
      "['中国', '慈善', '捐款', '最多', '哪些']\n",
      "['亿万', '富婆', '小妹', '臀围', '亚洲', '迷死人', '斯托', '戴耳圈', '爱美']\n",
      "['广州', 'D2', '神奇', '动物', '哪里']\n",
      "['湖南', '华中', '航天', '北斗', '卫星', '应用', '公司', '违法', '逃汇', '遭罚', '395', '万元']\n",
      "['人人', '幻想', '睡后', '收入']\n",
      "['旅游', '景区', '飞机', '大炮', '坦克', '这些', '现代', '兵器', '装备', '哪里', '知道']\n",
      "['究竟', '腊梅', '还是', '蜡梅', '到底', '哪个']\n",
      "['阿坝州', '理县', '小朋友', '感受', '民族', '民俗文化', '视频']\n",
      "['后院起火', '普京', '核战争', '避难所', '突然', '撬门', '偷窃', '盗贼', '有备而来']\n",
      "['本田', '终于', '发飙', '油耗', '4L', '标配', 'ESP', '性价比', '飞度', '10', '条街']\n",
      "['东莞', '塔雷', '张民志', '我国', '制造业', '数控机床', '生产', '模式', '即将', '迎来', '革命']\n",
      "['原汁原味', '联大', '牵动', '神思']\n",
      "['CFPLS12', '赛场', '观察', '季后赛', '数据', '大盘']\n",
      "['美国', '是不是', '分裂主义', '国家']\n",
      "['内外交困', '内塔尼亚胡', '是不是', '失去', '以色列', '统治']\n",
      "['上海', '民办', '中小学', '报名', '降温', '预计', '录取', '比例', '大幅', '上升']\n"
     ]
    }
   ],
   "source": [
    "# 测试一下分类效果\n",
    "# 分三类： 文娱看点 社会民生 国际时事\n",
    "for i in range(200):\n",
    "    if labels[i] == 2:\n",
    "        print(contents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化Embedding类，并且为文本打上标签\n",
    "ebd = Embedding(trained_dict=trained_dict,data=contents,args=args)\n",
    "ebd.get_words()\n",
    "ebd.get_id()\n",
    "ebd.get_labels(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 对比与总结\n",
    "我们尝试了两种无监督分类方法，虽然两种分类都存在一些文本被不正确的归为一类，但考虑到完全无监督没有经过训练的情况下，两种方法都展现了一定的效果。最终我们认为LDA模型更具有可解释性，且分类效果更好一些。因此我们最后采取LDA模型为文本建立标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4. News Classification (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 数据集预处理和划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Initial_Embedding():\n",
    "    def __init__(self,ebd,args) -> None:\n",
    "        self.dict_words = ebd.dict_words    # 单词映射到自然数的字典 ，包括了[PAD] [UNK]\n",
    "        self.trained_dict = ebd.trained_dict  # 下载的预训练的词典：词与word_vector的对应，未做更多处理\n",
    "        self.embedding_matrix = ebd.embedding_matrix # word embedding矩阵，每个word_vector对应的下标id为相应的词\n",
    "        self.embedding_dim = args['len_feature'] # embedding dim : 300\n",
    "        self.data = ebd.data # 分词后的总数据集\n",
    "        self.labels = ebd.labels\n",
    "        self.sentence_matrix = ebd.sentence_matrix   # 数据集中句子的矩阵表示（每个词为一个自然数）\n",
    "        self.train = None\n",
    "        self.dev = None\n",
    "        self.test = None\n",
    "        self.train_y = None\n",
    "        self.dev_y = None\n",
    "        self.test_y = None\n",
    "        \n",
    "        for idx in range(len(self.data)):\n",
    "            if len(self.data[idx]) > args['truncated']:\n",
    "                self.data[idx] = self.data[idx][0:args['truncated']]\n",
    "    \n",
    "    def data_split(self,args = args):\n",
    "        num = len(self.data)\n",
    "        train_num = int(num * args['train_rate'])\n",
    "        dev_num = int(num * args['dev_rate'])\n",
    "        self.train = self.sentence_matrix[0:train_num]\n",
    "        self.dev = self.sentence_matrix[train_num:train_num + dev_num]\n",
    "        self.test = self.sentence_matrix[train_num + dev_num:]\n",
    "        self.train_y = self.labels[0:train_num]\n",
    "        self.dev_y = self.labels[train_num:train_num + dev_num]\n",
    "        self.test_y = self.labels[train_num + dev_num:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Initial_Embedding(ebd=ebd,args=args)\n",
    "embedding.data_split(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class ClsDataset(Dataset):\n",
    "    def __init__(self,sentence,labels):\n",
    "        super(ClsDataset,self).__init__()\n",
    "        self.sentence = sentence\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.sentence[index],self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentence)\n",
    "\n",
    "train_set = ClsDataset(sentence=embedding.train,labels = embedding.train_y)\n",
    "dev_set = ClsDataset(sentence=embedding.dev,labels = embedding.dev_y)\n",
    "test_set = ClsDataset(sentence=embedding.test,labels=embedding.test_y)\n",
    "\n",
    "def collate_fn(batch_data):\n",
    "    sentence, labels = zip(*batch_data)\n",
    "    sentences = [torch.LongTensor(sent) for sent in sentence]  # 把句子变成Longtensor类型\n",
    "    padded_sents = pad_sequence(sentences, batch_first=True, padding_value=0)  # 自动padding操作！！！\n",
    "    return torch.LongTensor(padded_sents), torch.LongTensor(labels)\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size = args['batch_size'],shuffle=False,drop_last=True,collate_fn=collate_fn)\n",
    "dev_loader = DataLoader(dev_set,batch_size = args['batch_size'],shuffle=False,drop_last=True,collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set,batch_size = args['batch_size'],shuffle=False,drop_last=True,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self,args = args,init_embedding = embedding):\n",
    "        super(CNNModel,self).__init__()\n",
    "        self.dropout = nn.Dropout(args['dropout'])\n",
    "        # self.embedding = nn.Embedding(num_embeddings=len(init_embedding.embedding_matrix),embedding_dim=args['len_feature'],weight = torch.tensor(init_embedding.embedding_matrix)).cuda()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(init_embedding.embedding_matrix),padding_idx=0,freeze=False)\n",
    "        self.filter_num = args['filter_num']\n",
    "        self.len_feature = args['len_feature']\n",
    "        self.branch2xd = nn.Sequential(\n",
    "            nn.Conv2d(1,self.filter_num,kernel_size=(2,embedding_dim),padding = (1,0)),# 这里pad是为了为了防止某一批次单词数量过少无法做卷积，Padding added to all four sides\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.branch3xd = nn.Sequential(\n",
    "            nn.Conv2d(1,self.filter_num,kernel_size=(3,embedding_dim),padding=(1,0)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.branch4xd = nn.Sequential(\n",
    "            nn.Conv2d(1,self.filter_num,kernel_size=(4,embedding_dim),padding = (2,0)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.branch5xd = nn.Sequential(\n",
    "            nn.Conv2d(1,self.filter_num,kernel_size=(5,embedding_dim),padding=(2,0)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.fc = nn.Linear(4*self.filter_num,args['num_class'])\n",
    "        \n",
    "    def forward(self,X):\n",
    "        # 接收某一batch的输入 [b,l] b:batch_size, l:seq_length (after padding in this batch)\n",
    "        X = self.embedding(X).view(X.shape[0], 1, X.shape[1], self.len_feature) #[b,1,h,w] h:即为seq_length, w:len_feature:300\n",
    "        X = self.dropout(X)\n",
    "        conv1 = self.branch2xd(X).squeeze(3) #[b,filter_num,h,1] 然后丢弃最后一个维度(3) 之后再进行最大池化(池化会针对维度h)\n",
    "        conv2 = self.branch3xd(X).squeeze(3)\n",
    "        conv3 = self.branch4xd(X).squeeze(3)\n",
    "        conv4 = self.branch5xd(X).squeeze(3)\n",
    "        pool1 = F.max_pool1d(conv1, conv1.shape[2])\n",
    "        pool2 = F.max_pool1d(conv2, conv2.shape[2])\n",
    "        pool3 = F.max_pool1d(conv3, conv3.shape[2])\n",
    "        pool4 = F.max_pool1d(conv4, conv4.shape[2])\n",
    "        # 经过poolinig, 现在是 [b,filter_num,1]\n",
    "        pool = torch.cat([pool1, pool2, pool3, pool4], 1).squeeze(2) \n",
    "        out_put = self.fc(pool)\n",
    "        return out_put\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 25, 300])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# a = torch.ones(25, 300)\n",
    "# b = torch.ones(22, 300)\n",
    "# c = torch.ones(15, 300)\n",
    "# pad_sequence([a, b, c],batch_first = True).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "        - preds：预测值，二分类时，shape=[N, 1]，N为样本数量，多分类时，shape=[N, C]，C为类别数量\n",
    "        - labels：真实标签，shape=[N, 1]\n",
    "    输出：\n",
    "        - 准确率：shape=[1]\n",
    "    \"\"\"\n",
    "    labels = torch.tensor(labels)\n",
    "    preds = torch.argmax(preds,dim=1)\n",
    "    labels = labels.reshape(-1)\n",
    "    return torch.mean((preds == labels).float()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote-home/pjli/anaconda3/envs/nlptorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "preds = torch.tensor([[0.4,0.5,0.1],[0.9,0.03,0.03]])\n",
    "labels = [1,0]\n",
    "accuracy(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.003) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 5. Conclusion (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Reference\n",
    "List your references here.\n",
    "\n",
    "1. https://blog.csdn.net/kobeyu652453/article/details/107559519\n",
    "2. https://github.com/blei-lab/lda-c\n",
    "3. https://blog.csdn.net/v_july_v/article/details/41209515#t13"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('nlptorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ea09dad9c5cbe1dfe16e763c2b738244c66046026912720282114a9d0931e6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
